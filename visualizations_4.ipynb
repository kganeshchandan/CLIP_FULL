{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import yaml\n",
    "import pandas as pd\n",
    "from PrepareData import prepare_data\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.nn import functional as F\n",
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import seaborn as sns\n",
    "from architecture import CLIP\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = pickle.load(open('./checkpoints/FULL_COMBINED_RANDOM_SMILES/val_ids.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_deterministic(random_seed = 0):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_deterministic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_epoch 561\n",
      "best_clip_epoch 578\n",
      "best_recon_epoch 561\n",
      "best_total_loss 0.09075611144304276\n",
      "best_clip_loss 0.011152334472280928\n",
      "best_recon_loss 0.0794648565351963\n"
     ]
    }
   ],
   "source": [
    "config = yaml.safe_load(open('./checkpoints/FULL_COMBINED_RANDOM_SMILES/config.yaml', 'r'))\n",
    "logs = pickle.load(open('./checkpoints/FULL_COMBINED_RANDOM_SMILES/logs.pickle', 'rb'))\n",
    "for key in logs:\n",
    "    if \"best\" in key:\n",
    "        print(key, logs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08bc524d3f84d7fb0c995f69a0df205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7dd9c7022246d4978879c43e3eb68a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES WILL BE RANDOMIZED\n"
     ]
    }
   ],
   "source": [
    "model = load_model(config['train']['checkpoint_dir'], type=\"best_clip\")\n",
    "model.eval()\n",
    "dataloaders, max_charge, num_species = prepare_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home2/kanakala.ganesh/miniconda3/envs/sbdd-env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "50it [00:20,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "all_ids = []\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(dataloaders['val'])):    \n",
    "        data = {k: v.to(device) for k, v in data.items()}\n",
    "        mol_latents, spec_latents, smile_preds, logit_scale, ids = model(data)\n",
    "        all_ids.append(ids.detach().cpu())\n",
    "all_ids = torch.cat(all_ids, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for id in val_ids:\n",
    "    if id in all_ids:\n",
    "        count += 1 \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:28,  2.83it/s]\n"
     ]
    }
   ],
   "source": [
    "molembeds = []\n",
    "specembeds = []\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(dataloaders['train'])):    \n",
    "        data = {k: v.to(device) for k, v in data.items()}\n",
    "        mol_latents, spec_latents, smile_preds, logit_scale, ids = model(data)\n",
    "        molembeds.append(mol_latents.detach().cpu())\n",
    "        specembeds.append(spec_latents.detach().cpu())\n",
    "    del mol_latents, spec_latents, smile_preds, logit_scale, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_molembeds = torch.cat(molembeds, 0)\n",
    "train_specembeds = torch.cat(specembeds, 0)\n",
    "from train_utils import decoder_performance\n",
    "from train_utils import top_scores, decoder_performance, distance_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_scores(mat1, mat2):\n",
    "    hits = []\n",
    "    tops = [1,2,3,4,5,10]\n",
    "    score = [0] * (len(tops))\n",
    "\n",
    "    for i in tqdm(range(mat1.shape[0])):\n",
    "        sims = mat2 @ mat1[i].t()\n",
    "        for k in range(len(tops)):\n",
    "            max_sims, ids = torch.topk(sims, tops[k])\n",
    "            if (i) in ids:\n",
    "                score[k] += 1\n",
    "\n",
    "    for i in range(len(tops)):\n",
    "        score[i] = score[i] / mat1.shape[0]\n",
    "\n",
    "    return np.array(tops), np.array(score ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 16313/100000 [00:57<04:37, 301.73it/s]"
     ]
    }
   ],
   "source": [
    "tops, scores = top_scores(train_specembeds, train_molembeds)\n",
    "for k, acc in zip(tops, scores):\n",
    "    # print(\"Full Top {} Spec\".format(k), acc)\n",
    "    print({\"Full Top {} Spec Acc {}\".format(k, acc)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbdd-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
