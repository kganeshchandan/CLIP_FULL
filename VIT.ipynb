{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['data'] = {\"qm9_broad_ir_path\":'/home2/kanakala.ganesh/ir_data/qm9_broad_ir.pkl',\n",
    "                  \"vocab_path\":'/home2/kanakala.ganesh/CLIP_PART_1/data/qm9_vocab.pkl',\n",
    "                  \"datafiles\" : {\n",
    "                        'train': '/home2/kanakala.ganesh/ir_data/raw_train.pickle',\n",
    "                        'test':  '/home2/kanakala.ganesh/ir_data/raw_test.pickle',\n",
    "                        'val':   '/home2/kanakala.ganesh/ir_data/raw_val.pickle'\n",
    "                        },\n",
    "                  \"normalization\" : \"unit\",\n",
    "                  \"shuffle\": True,\n",
    "                  \"batch_size\":128,\n",
    "                  \"seq_len\":70,\n",
    "                  \"splits\":[0.9, 0.1, 0.1],\n",
    "                  \"num_workers\":16\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0989c0095b4bc58ef9d95a6603bdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29134aea05694fe8b55f958b1d9a2a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PrepareData import prepare_data\n",
    "dataloaders, max_charge, num_species = prepare_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index torch.Size([128])\n",
      "decoder_inp torch.Size([128, 70])\n",
      "decoder_tgt torch.Size([128, 70])\n",
      "IR torch.Size([128, 1801])\n",
      "tgt_padding_mask torch.Size([128, 70])\n",
      "num_atoms torch.Size([128])\n",
      "charges torch.Size([128, 29])\n",
      "positions torch.Size([128, 29, 3])\n",
      "one_hot torch.Size([128, 29, 5])\n",
      "atom_mask torch.Size([128, 29])\n",
      "edge_mask torch.Size([107648, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i , data in enumerate(dataloaders['train']):\n",
    "    data\n",
    "    for j in data:\n",
    "        print(j, data[j].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['spectra_encoder'] = {\n",
    "    'd_ff': 1024,\n",
    "    'dropout': 0.0,\n",
    "    'dropout_emb': 0.1,\n",
    "    'h_dim': 128,\n",
    "    'max_time_steps': 1000,\n",
    "    'num_heads': 5,\n",
    "    'num_layers': 5,\n",
    "    'output_size': 512,\n",
    "    'patch_size': 7,\n",
    "    'use_clf_token': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vit import ViT\n",
    "\n",
    "model = ViT(\n",
    "            patch_size = config['spectra_encoder']['patch_size'], \n",
    "            num_layers = config['spectra_encoder']['num_layers'], \n",
    "            h_dim = config['spectra_encoder']['h_dim'], \n",
    "            num_heads =config['spectra_encoder']['num_heads'], \n",
    "            output_size = config['spectra_encoder']['output_size'], \n",
    "            d_ff=config['spectra_encoder']['d_ff'], \n",
    "            max_time_steps=config['spectra_encoder']['max_time_steps'], \n",
    "            use_clf_token=config['spectra_encoder']['use_clf_token'],\n",
    "            dropout = config['spectra_encoder']['dropout'],\n",
    "            dropout_emb = config['spectra_encoder']['dropout_emb']\n",
    "            \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def forward_pass(model, dataloader):\n",
    "    for i , data in enumerate(dataloader):\n",
    "        data\n",
    "        break\n",
    "    \n",
    "    spectra = data['IR']\n",
    "    spectra = torch.unsqueeze(spectra,1)\n",
    "    spectra = torch.unsqueeze(spectra,1)\n",
    "    spectra = spectra.to(torch.float32)\n",
    "    # [B, C, H, W]\n",
    "    preds = model(spectra)\n",
    "    \n",
    "    \n",
    "    print(preds.shape)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 512])\n"
     ]
    }
   ],
   "source": [
    "out = forward_pass(model, dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbdd-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
